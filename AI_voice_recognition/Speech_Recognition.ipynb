{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "U9m_p9oRqEWu"
   },
   "source": [
    "TensorFlow opublikował Speech Commands Datasets. Baza danych zawiera 65 tysięcy jednosekundowych nagrań 30 krótkich słów w języku angielskim, wypowiedzianych przez kilka ttsięcy różnych osób. W trakcie laboratorium zostaną użyte głębokie sieci neuronowe do rozpoznawania tych słów.\n",
    "\n",
    "Baza nagrań może być pobrana stąd [tutaj](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge).\n",
    "\n",
    "**Implementacja modelu Speech-to-Text w Python'ie od podstaw**\n",
    "\n",
    "**Import niezbędnych bibliotek**\n",
    "\n",
    "W pierwszej kolejności importujemy biblioteki niezbędne do przetwarzania analizowanych danych. LibROSA i SciPy są bibiotekami Python'a używanymi do przetwarzania sygnałów audio."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip freeze --local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPWlIEcSqEWw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PSXLBpDqEWz",
    "outputId": "c445d03c-0aa1-4a18-b8d1-cff3d4aa23a6"
   },
   "outputs": [],
   "source": [
    "os.listdir('/home/ilona/Desktop/Literatura/SemestrVII/Systemy_Glosowe/voice_sys/AI_voice_recognition\n",
    "')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "kDzlfWQkqEW3"
   },
   "source": [
    "**Eksploracja i wizualizacja danych**\n",
    "\n",
    "Eksploracja i wizualizacja danych pomaga zrozumieć zawartość danych oraz transformację danych w trakcie procesu ich przetwarzania. \n",
    "\n",
    "**Wizualizacja sygnału audio w dziedzinie czasu**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EXrIaovqEW3",
    "outputId": "433e9f62-51f1-4c2b-af61-e4fb8e3bc48f"
   },
   "outputs": [],
   "source": [
    "train_audio_path = '../input/tensorflow-speech-recognition-challenge/train/audio/'\n",
    "samples, sample_rate = librosa.load(train_audio_path+'yes/0a7c2a8d_nohash_0.wav', sr = 16000)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('Raw wave of ' + '../input/train/audio/yes/0a7c2a8d_nohash_0.wav')\n",
    "ax1.set_xlabel('time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "IyG3ej2tqEW6"
   },
   "source": [
    "**Częstotliwość próbkowania **\n",
    "\n",
    "Sprawdźmy, jaka jest częstotliwość próbkowania sygnału audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmK92_hbqEW7",
    "outputId": "87da7f26-097a-445e-89fd-225854a14bc2"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su9k90vTqEW-",
    "outputId": "543d0fff-7bfa-4c97-b9a1-22dba39a5956"
   },
   "outputs": [],
   "source": [
    "print(sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "ikT_Bw-dqEXA"
   },
   "source": [
    "**Resampling**\n",
    "\n",
    "Z informacji zwróconej przez funkcję load z biblioteki LibROSA wynika, że częstotliwośc próbkowania nagrań to 16000 Hz. Wykonamy teraz resamplig sygnału usuwając z sygnału częstotliwości powyżej 8000 Hz. Głowym celem tego zabiegu jest ograniczenie czasu treningu sieci neuronowej. Częstotliwości słyszalne przez ludzkie ucho mieszczą się w przedziale do ok. 22 000 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r03tEvLxqEXB",
    "outputId": "bd64cf16-d6fb-4911-d4e3-05e2cf2da39c"
   },
   "outputs": [],
   "source": [
    "samples = librosa.resample(samples, sample_rate, 8000)\n",
    "ipd.Audio(samples, rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "bew8h8giqEXE"
   },
   "source": [
    " A teraz sprawdźmy ile jest w bazie danych nagrań dla każdego polecenia głosowego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9xjDoz4qEXF"
   },
   "outputs": [],
   "source": [
    "labels=os.listdir(train_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOwj9vgVqEXH",
    "outputId": "6a4d1ccf-cc85-4639-e930-4f09dffcae92"
   },
   "outputs": [],
   "source": [
    "#dla każdej etykiety z listy kartotek znajdujemy liczbę plików audio w tej kartotece\n",
    "no_of_recordings=[]\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    no_of_recordings.append(len(waves))\n",
    "    \n",
    "#wykres\n",
    "plt.figure(figsize=(30,5))\n",
    "index = np.arange(len(labels))\n",
    "plt.bar(index, no_of_recordings)\n",
    "plt.xlabel('Commands', fontsize=12)\n",
    "plt.ylabel('No of recordings', fontsize=12)\n",
    "plt.xticks(index, labels, fontsize=15, rotation=60)\n",
    "plt.title('No. of recordings for each command')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jV67CEiiqEXK"
   },
   "outputs": [],
   "source": [
    "labels=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "88Dna42lqEXM"
   },
   "source": [
    "**Długość nagrań**\n",
    "\n",
    "A teraz sprawdźmy, jak długie są nagrania poleceń głosowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9IDSXZ5qEXN",
    "outputId": "a3b8efba-a8fc-4d71-93c8-bc6bbd2d0c91"
   },
   "outputs": [],
   "source": [
    "duration_of_recordings=[]\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        sample_rate, samples = wavfile.read(train_audio_path + '/' + label + '/' + wav)\n",
    "        duration_of_recordings.append(float(len(samples)/sample_rate))\n",
    "    \n",
    "plt.hist(np.array(duration_of_recordings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "S6TD3WjiqEXP"
   },
   "source": [
    "**Preprocessing sygnałów audio**\n",
    "\n",
    "W efekcie przeprowadzonej eksploracji danych ustaliliśmy, że w przypadku niektórych nagrań ich długość jest mniejsza, niż jedna sekunda oraz, że częstotliwość próbkowania wynosi 16 tys Hz. Spośród wszystkich nagrań do dalszej pracy wybieramy tylko te z komendami zapisanymi w tablicy labels. Wykonujemy resampling nagrań do częstotliwości 8 tys HZ i pozostawiamy tylko nagrania jednosekundowe (złożone z 8000 próbek).\n",
    "\n",
    "\n",
    "Kod realizujący założone kroki preprocessingu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJI86zdTqEXQ",
    "outputId": "635b9281-c3da-44e1-e283-624656d2b18f"
   },
   "outputs": [],
   "source": [
    "train_audio_path = '../input/tensorflow-speech-recognition-challenge/train/audio/'\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if(len(samples)== 8000) : \n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "DAzJ6kXBqEXT"
   },
   "source": [
    "Konwertujemy etykiety tekstowe do kodów całkowitoliczbowych, wymaganych do treningu klasyfikatora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_st6asyHqEXU"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(all_label)\n",
    "classes= list(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "xU8Pqgu5qEXW"
   },
   "source": [
    "Zaczyna się magia frameworku keras...\n",
    "Konwertujemy całkowitoliczbowe etykiery do jednego wektora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZZyaahuqEXX",
    "outputId": "6778b5b7-5641-4a9a-f4e5-8fa0237f906b"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "qG98IAOKqEXZ"
   },
   "source": [
    "Przerabiamy macierze 2D na 3D ponieważ takiego wejścia spodziewa się sieć, która będzie użyta do rozpoznawania komend głosowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzFvLjcuqEXa"
   },
   "outputs": [],
   "source": [
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "6Ah5E2lOqEXc"
   },
   "source": [
    "**Wybór zbioru treningowego i walidacyjnego**\n",
    "\n",
    "Użyjemy 80% danych do treningu, a pozostałe 20% do walidacji wytrenowanego modelu:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TV3ioRhpqEXd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "sXQOOT6VqEXg"
   },
   "source": [
    "**Wybór architektury sieci dla problemu rozpozawaia komed głosowych**\n",
    "\n",
    "Model speech-to-text zostanie zbudowany w oparciu o sieć conv1d. Conv1d to konwolucyjna sieć neuronowa, wykonująca konwolucję tylko w jedym wymiarze. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "iY1pEi7-qEXg"
   },
   "source": [
    "**Budowa modelu**\n",
    "\n",
    "Budujemy model korzystając z API frameworku Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PEw1tIIqEXh",
    "outputId": "8ded4d67-bdff-4f47-ab03-940ad22c5a19"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(8000,1))\n",
    "\n",
    "#First Conv1D layer\n",
    "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Second Conv1D layer\n",
    "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Third Conv1D layer\n",
    "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Fourth Conv1D layer\n",
    "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Flatten layer\n",
    "conv = Flatten()(conv)\n",
    "\n",
    "#Dense Layer 1\n",
    "conv = Dense(256, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Dense Layer 2\n",
    "conv = Dense(128, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "TkjO7igWqEXk"
   },
   "source": [
    "Definiujemy \"loss function\" w oparciu o \"categorical cross-entropy\" - wybór odpowiedni dla problemu klasyfikacji wieloklasowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZWWbXFkqEXl",
    "outputId": "cd533d7b-b8db-4ee6-c43d-f51e2e137ba7"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "2L7VN0UAqEXq"
   },
   "source": [
    "\"Early stopping\" i \"model checkpoints\" to callback'i użyte w celu zatrzymania treningu sieci neuronowej w odpowiednim momencie (zanim zacznie się przetrenowanie) i w celu zapisania najlepszego uzyskanego modelu uzyskanego po każdej z epok treingu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOL9AMm8qEXq"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "wvMzc4eLqEXu"
   },
   "source": [
    "Trening i testowaie na zbiorze walidacyjnym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhjyBtmwqEXv",
    "outputId": "af37b331-e0bc-4c46-fdab-9f35113c3735"
   },
   "outputs": [],
   "source": [
    "history=model.fit(x_tr, y_tr ,epochs=3, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "pegQ8ATHqEXx"
   },
   "source": [
    "**Wykres diagnostyczny**\n",
    "\n",
    "Wizualizacja pomaga nam zrozumieć, jak działa sieć na danych treningiwych, a jak na walidacyjnych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1YT4xIVqEXy",
    "outputId": "4443b33a-bc32-4759-ab43-3ecf948c2f13"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "jDnRb-FhqEX1"
   },
   "source": [
    "**Ładujemy najlepszy zapamiętany model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkVaxSpAqEX2"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "fbmf8GdiqEX4"
   },
   "source": [
    "Definiujemy funkcję, która znajduje wyraz odpowiadający sygnałowi audio::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awpvuYhoqEX4"
   },
   "outputs": [],
   "source": [
    "def predict(audio):\n",
    "    prob=model.predict(audio.reshape(-1,8000,1))\n",
    "    index=np.argmax(prob[0])\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "YXCV7VOLqEX6"
   },
   "source": [
    "**Predykcja**\n",
    "Sprawdzamy działanie wytrenowanej sieci na zbiorze walidacyjnym (poniższy skrypt można uruchamiać wielokrotnie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWXQSCRtqEX7",
    "outputId": "ebf53289-3431-497d-8255-3d376126dfe3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "index=random.randint(0,len(x_val)-1)\n",
    "samples=x_val[index].ravel()\n",
    "print(\"Audio:\",classes[np.argmax(y_val[index])])\n",
    "ipd.Audio(samples, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPbWWndbqEX9",
    "outputId": "fdea926c-ce79-4a81-97b1-64edab9f718e"
   },
   "outputs": [],
   "source": [
    "print(\"Text:\",predict(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "jFHiB7_tqEYA"
   },
   "source": [
    "Poniższy skrypt prosi użytkownika o nagranie komendy głosowej. Proszę nagrać jedną z komend rozpoznawanych przez wytrenowaną sieć:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqrA9El0qEYB",
    "outputId": "8eaffd25-f1cb-420f-f536-5d18e0810c88"
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "samplerate = 16000  \n",
    "duration = 1 # seconds\n",
    "filename = 'stop.wav'\n",
    "print(\"start\")\n",
    "mydata = sd.rec(int(samplerate * duration), samplerate=samplerate,\n",
    "    channels=1, blocking=True)\n",
    "print(\"end\")\n",
    "sd.wait()\n",
    "sf.write(filename, mydata, samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "JlwAOCWYqEYE"
   },
   "source": [
    "Wczytajmy zapisany plik audio i sprawdźmy, jak radzi sobie z nim wytrenowana sieć:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIulLjAqqEYF",
    "outputId": "ee8f976d-f303-43da-e02a-a3ad4ec9bc67"
   },
   "outputs": [],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcGdKUJ7qEYI"
   },
   "outputs": [],
   "source": [
    "filepath='../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pnbjj3GVqEYK",
    "outputId": "a787865e-4ff8-497b-ebf6-b0010d239490"
   },
   "outputs": [],
   "source": [
    "#reading the voice commands\n",
    "samples, sample_rate = librosa.load(filepath + '/' + 'stop.wav', sr = 16000)\n",
    "samples = librosa.resample(samples, sample_rate, 8000)\n",
    "ipd.Audio(samples,rate=8000)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k77Tbt_gqEYM",
    "outputId": "28162b13-505b-4ce2-f037-9e964c23007d"
   },
   "outputs": [],
   "source": [
    "#converting voice commands to text\n",
    "predict(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "QUKmLaGJqEYO"
   },
   "source": [
    "Gratulacje! A teraz proszę sprawdzić skuteczność działania sieci na całym zbiorze walidacyjnym..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Speech Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
